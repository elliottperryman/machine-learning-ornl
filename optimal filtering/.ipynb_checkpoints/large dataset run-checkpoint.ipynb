{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from time import clock\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelen=3500\n",
    "noise_rms=20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    rng_state = random.get_state()\n",
    "    random.shuffle(a)\n",
    "    random.set_state(rng_state)\n",
    "    random.shuffle(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_trapezoid(rise_time, flat_top , tau):\n",
    "    length = wavelen\n",
    "    length = length+2*rise_time+flat_top;\n",
    "    p = zeros(length)\n",
    "    s = zeros(length)\n",
    "    input2 = zeros(length)\n",
    "    p[0] = s[0] = input2[0] = 0.;\n",
    "    for i in range(1,length):\n",
    "        input2[i] = s[i] = 0.;\n",
    "    input2[1]=1.;\n",
    "    tau = 1/(exp(1./tau)-1);\n",
    "    for i in range(1,length):\n",
    "        if i>=2*rise_time+flat_top:\n",
    "            d = input2[i]-input2[i-rise_time]-input2[i-rise_time-flat_top]+input2[i-2*rise_time-flat_top]\n",
    "        else:\n",
    "            if i>=rise_time+flat_top:\n",
    "                d = input2[i]-input2[i-rise_time]-input2[i-rise_time-flat_top]\n",
    "            else:\n",
    "                if i>=rise_time:\n",
    "                    d = input2[i]-input2[i-rise_time]\n",
    "                else:\n",
    "                    d = input2[i];\n",
    "        p[i] = p[i-1]+d;\n",
    "        s[i] = s[i-1]+p[i]+tau*d;\n",
    "    for i in range(length):\n",
    "        s[i] = s[i]/(rise_time*tau);\n",
    "    \n",
    "    res = fft.rfft(s)\n",
    "    return res[:-rise_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_gen():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_generic(X, fft_func, *args):\n",
    "    batchsize = len(X)\n",
    "    X_ = X.reshape(batchsize,wavelen).copy()\n",
    "    fft_filter = fft_func(*args)\n",
    "    for i in range(batchsize):\n",
    "        X_[i] = fft.irfft(fft.rfft(X_[i])*fft_filter)\n",
    "    return X_.reshape(batchsize,wavelen,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_synth_pulse_realistic(amp, T0, wf):\n",
    "    length = len(wf)\n",
    "    cc_slow = 2.5+0.4*random.normal(); cc_slow=cc_slow/(cc_slow+1); ##charge collection slow time constant\n",
    "\n",
    "    cc_fast = 1./2.5; #charge collection fast time constant\n",
    "    alpha_cr = 1250./(1250.+1.); #fall time of output\n",
    "    alpha_rc1 = 1./2.75;\n",
    "    alpha_rc2 = 1./2.75;\n",
    "    step=zeros(2);charge=zeros(2);cur_s=zeros(2);cur_f=zeros(2);cr=zeros(2);rc1=zeros(2);rc2=zeros(2);\n",
    "    for i in range(length):\n",
    "        if i>=T0:\n",
    "            step[i%2]=1.\n",
    "        else:\n",
    "            step[i%2]=0.\n",
    "        cur_s[i%2]=cc_slow*(cur_s[(i+1)%2]+step[i%2]-step[(i+1)%2]);\n",
    "        cur_f[i%2]=cc_fast*(cur_s[i%2]-cur_f[(i+1)%2])+cur_f[(i+1)%2];\n",
    "        charge[i%2]=charge[(i+1)%2]+amp*cur_f[i%2]*(1./cc_slow-1.);\n",
    "        cr[i%2]=alpha_cr*(cr[(i+1)%2]+charge[i%2]-charge[(i+1)%2]);\n",
    "        rc1[i%2]=alpha_rc1*(cr[i%2]-rc1[(i+1)%2])+rc1[(i+1)%2];\n",
    "        rc2[i%2]=alpha_rc2*(rc1[i%2]-rc2[(i+1)%2])+rc2[(i+1)%2];\n",
    "        wf[i]=rc2[i%2];\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def superimpose_noise(wf, stdDev):\n",
    "    length=len(wf)\n",
    "    fin = open('config/power_spectrum.dat', 'r')\n",
    "    powerspectrum = array(str(fin.read()).split(), dtype=float64)\n",
    "    fin.close()\n",
    "    my_array = zeros((65533,2))\n",
    "    my_array[0][0]= -114.962\n",
    "    my_array[0][0]= 0.\n",
    "    for i in range(1,32767):\n",
    "        phase = 2.*pi*(random.randint(1, 10000000 + 1)%10000000)/10000000.\n",
    "        my_array[i][0]=powerspectrum[i-1]*cos(phase);\n",
    "        my_array[65532-i+1][0]=my_array[i][0]\n",
    "        my_array[i][1]=powerspectrum[i-1]*sin(phase);\n",
    "        my_array[65532-i+1][1]= -1*(my_array[i][1])\n",
    "    my_array = (my_array[:,0]+my_array[:,1].astype(complex_))\n",
    "    my_array = fft.irfft(my_array)\n",
    "    for i in range(length):\n",
    "        wf[i]= length*stdDev*my_array[i]*1.633953736 # adjusted factor here since fftw3 is unnormalized fft\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_realistic_batch(batchsize):\n",
    "    energies = random.randint(200,2500,size=(batchsize))\n",
    "    delays = random.randint(1,40,size=(batchsize))\n",
    "    percent = random.random(batchsize)\n",
    "    T0s = random.randint(900,1101,batchsize)\n",
    "    \n",
    "    rand_choices = empty((batchsize,3))\n",
    "    rand_choices[:,0] = energies\n",
    "    rand_choices[:,1] = delays\n",
    "    rand_choices[:,2] = percent\n",
    "    \n",
    "    X = empty((batchsize,wavelen))\n",
    "    y = append(ones(int(batchsize*0.5)), zeros(batchsize-int(batchsize*0.5)))\n",
    "    \n",
    "    tmp = empty(wavelen)\n",
    "    tmp2= empty(wavelen)\n",
    "    noise = empty(wavelen)\n",
    "\n",
    "    # generate an 1:1 ratio of pileup to no pileup then shuffle them\n",
    "    for i in range(int(batchsize*0.5)):\n",
    "        gen_synth_pulse_realistic(rand_choices[i][0]*rand_choices[i][2],T0s[i],tmp)\n",
    "        gen_synth_pulse_realistic(rand_choices[i][0]*(1-rand_choices[i][2]),T0s[i]+rand_choices[i][1],tmp2)\n",
    "        superimpose_noise(noise,noise_rms)\n",
    "        X[i] = tmp+tmp2+noise\n",
    "    for i in range(int(batchsize*0.5),batchsize):\n",
    "        gen_synth_pulse_realistic(rand_choices[i][0],T0s[i],tmp)\n",
    "        superimpose_noise(noise,noise_rms)\n",
    "        X[i] = tmp+noise\n",
    "        \n",
    "    \n",
    "    shuffle_in_unison(X,y)\n",
    "    return X.reshape(batchsize,wavelen,1),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_synth_pulse(amp, T0, wf):\n",
    "    length = len(wf)\n",
    "    cc_slow = 2.5; cc_slow=cc_slow/(cc_slow+1); ##charge collection slow time constant\n",
    "\n",
    "    cc_fast = 1./2.5; #charge collection fast time constant\n",
    "    alpha_cr = 1250./(1250.+1.); #fall time of output\n",
    "    alpha_rc1 = 1./2.75;\n",
    "    alpha_rc2 = 1./2.75;\n",
    "    step=zeros(2);charge=zeros(2);cur_s=zeros(2);cur_f=zeros(2);cr=zeros(2);rc1=zeros(2);rc2=zeros(2);\n",
    "    for i in range(length):\n",
    "        if i>=T0:\n",
    "            step[i%2]=1.\n",
    "        else:\n",
    "            step[i%2]=0.\n",
    "        cur_s[i%2]=cc_slow*(cur_s[(i+1)%2]+step[i%2]-step[(i+1)%2]);\n",
    "        cur_f[i%2]=cc_fast*(cur_s[i%2]-cur_f[(i+1)%2])+cur_f[(i+1)%2];\n",
    "        charge[i%2]=charge[(i+1)%2]+amp*cur_f[i%2]*(1./cc_slow-1.);\n",
    "        cr[i%2]=alpha_cr*(cr[(i+1)%2]+charge[i%2]-charge[(i+1)%2]);\n",
    "        rc1[i%2]=alpha_rc1*(cr[i%2]-rc1[(i+1)%2])+rc1[(i+1)%2];\n",
    "        rc2[i%2]=alpha_rc2*(rc1[i%2]-rc2[(i+1)%2])+rc2[(i+1)%2];\n",
    "        wf[i]=rc2[i%2];\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trap_gen_batch(batchsize):\n",
    "    # trapezoid filter version...\n",
    "    # speedy function without rise time spread and without noise spectrum\n",
    "    energies = random.randint(200,2500,size=(batchsize)) #*2500\n",
    "    delays = random.random(batchsize)*40\n",
    "    percent = random.random(batchsize)\n",
    "    #T0s = random.normal(loc=1000, scale=30, size=batchsize).round().astype(int)\n",
    "    T0s = random.randint(900,1101,batchsize)\n",
    "\n",
    "    rand_choices = empty((batchsize,3))\n",
    "    rand_choices[:,0] = energies\n",
    "    rand_choices[:,1] = delays\n",
    "    rand_choices[:,2] = percent\n",
    "    \n",
    "    X = empty((batchsize,wavelen))\n",
    "    y = append( ones(int(batchsize/2)), zeros(batchsize-int(batchsize/2)))\n",
    "    \n",
    "    noise = random.normal(scale=noise_rms,size=(batchsize,wavelen))\n",
    "    tmp = empty(wavelen)\n",
    "    tmp2= empty(wavelen)\n",
    "    trap_ = fft_trapezoid(100,0,1250.)\n",
    "    \n",
    "    # generate an 1:1 ratio of pileup to no pileup then shuffle them\n",
    "    for i in range(int(batchsize/2)):\n",
    "        gen_synth_pulse(rand_choices[i][0]*rand_choices[i][2],T0s[i],tmp)\n",
    "        gen_synth_pulse(rand_choices[i][0]*(1-rand_choices[i][2]),T0s[i]+rand_choices[i][1],tmp2)\n",
    "        X[i] = fft.irfft(trap_*fft.rfft(tmp+tmp2+noise[i]))\n",
    "    for i in range(int(batchsize/2),batchsize):\n",
    "        gen_synth_pulse(rand_choices[i][0],T0s[i],tmp)\n",
    "        X[i] = fft.irfft(trap_*fft.rfft(tmp+noise[i]))\n",
    "        \n",
    "    shuffle_in_unison(X,y)\n",
    "    return X.reshape(batchsize,wavelen,1),y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trapezoid Filter CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_davids_data():\n",
    "    os.system(\"./bin/pulse_generation\")\n",
    "    train_X = loadtxt('data/final.csv')\n",
    "    train_y = append(zeros(int(len(train_X)/2)),ones(int(len(train_X)/2)))\n",
    "    shuffle_in_unison(train_X,train_y)\n",
    "\n",
    "    trap_ = fft_trapezoid(10,0,1250.)\n",
    "    for i in range(len(train_X)):\n",
    "        train_X[i] -= mean(train_X[i][:900])\n",
    "        train_X[i] = fft.irfft(trap_*fft.rfft(train_X[i]))\n",
    "        train_X[i] = train_X[i]/max(train_X[i])\n",
    "    train_X = train_X.reshape(len(train_X),wavelen,1)\n",
    "    return train_X, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_aarons_data():\n",
    "    os.system(\"./aaron_gen/bin/pulse_generation\")\n",
    "    train_X = loadtxt('./aaron_gen/data/final.csv')\n",
    "    train_y = append(zeros(int(len(train_X)/2)),ones(int(len(train_X)/2)))\n",
    "    shuffle_in_unison(train_X,train_y)\n",
    "\n",
    "    trap_ = fft_trapezoid(10,0,1250.)\n",
    "    for i in range(len(train_X)):\n",
    "        train_X[i] -= mean(train_X[i][:900])\n",
    "        train_X[i] = fft.irfft(trap_*fft.rfft(train_X[i]))\n",
    "        train_X[i] = train_X[i]/max(train_X[i])\n",
    "    train_X = train_X.reshape(len(train_X),wavelen,1)\n",
    "    return train_X, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"./bin/pulse_generation\")\n",
    "train_X = loadtxt('data/final.csv')\n",
    "val_y = append(zeros(int(len(train_X)/2)),ones(int(len(train_X)/2)))\n",
    "shuffle_in_unison(train_X,val_y)\n",
    "trap_ = fft_trapezoid(10,0,1250.)\n",
    "for i in range(len(train_X)):\n",
    "    train_X[i] -= mean(train_X[i][:900])\n",
    "    train_X[i] = fft.irfft(trap_*fft.rfft(train_X[i]))\n",
    "    train_X[i] = train_X[i]/max(train_X[i])\n",
    "val_x = train_X.reshape(len(train_X),wavelen,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "36000/36000 [==============================] - 53s 1ms/step - loss: 0.4104 - acc: 0.8111\n",
      "Epoch 2/5\n",
      "36000/36000 [==============================] - 51s 1ms/step - loss: 0.2892 - acc: 0.8868\n",
      "Epoch 3/5\n",
      "36000/36000 [==============================] - 52s 1ms/step - loss: 0.2587 - acc: 0.9003\n",
      "Epoch 4/5\n",
      "36000/36000 [==============================] - 52s 1ms/step - loss: 0.2242 - acc: 0.9166\n",
      "Epoch 5/5\n",
      "36000/36000 [==============================] - 51s 1ms/step - loss: 0.2047 - acc: 0.9238\n",
      "36000/36000 [==============================] - 18s 490us/step\n",
      "Accuracy is 0.8996388888888889\n",
      "Epoch 1/5\n",
      "36000/36000 [==============================] - 51s 1ms/step - loss: 0.2354 - acc: 0.9141\n",
      "Epoch 2/5\n",
      "36000/36000 [==============================] - 52s 1ms/step - loss: 0.2243 - acc: 0.9163\n",
      "Epoch 3/5\n",
      "36000/36000 [==============================] - 52s 1ms/step - loss: 0.2089 - acc: 0.9230\n",
      "Epoch 4/5\n",
      "36000/36000 [==============================] - 52s 1ms/step - loss: 0.1935 - acc: 0.9270\n",
      "Epoch 5/5\n",
      "36000/36000 [==============================] - 52s 1ms/step - loss: 0.1711 - acc: 0.9331\n",
      "36000/36000 [==============================] - 17s 486us/step\n",
      "Accuracy is 0.9248888888888889\n"
     ]
    }
   ],
   "source": [
    "model = model_gen()\n",
    "acc=0\n",
    "while(acc<0.91):\n",
    "    \n",
    "    os.system(\"./bin/pulse_generation\")\n",
    "    train_X = loadtxt('data/final.csv')\n",
    "    y = append(zeros(int(len(train_X)/2)),ones(int(len(train_X)/2)))\n",
    "    shuffle_in_unison(train_X,y)\n",
    "    trap_ = fft_trapezoid(10,0,1250.)\n",
    "    for i in range(len(train_X)):\n",
    "        train_X[i] -= mean(train_X[i][:900])\n",
    "        train_X[i] = fft.irfft(trap_*fft.rfft(train_X[i]))\n",
    "        train_X[i] = train_X[i]/max(train_X[i])\n",
    "    x = train_X.reshape(len(train_X),wavelen,1)\n",
    "    \n",
    "    model.fit(x,y,batch_size=64,epochs=5)\n",
    "    \n",
    "    acc = model.evaluate(val_x,val_y)[1]\n",
    "    print(\"Accuracy is \"+str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 17s 484us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21295314644277097, 0.9248888888888889]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_gen_no_dropout():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_drop = model_gen_no_dropout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_drop.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"logs/tmp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "36000/36000 [==============================] - 57s 2ms/step - loss: 0.3714 - acc: 0.8315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6cb73360b8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_drop.fit(val_x,val_y, batch_size=32, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_drop.load_weights(\"logs/tmp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 18s 489us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21295314644277097, 0.9248888888888889]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_drop.evaluate(val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "36000/36000 [==============================] - 56s 2ms/step - loss: 0.2414 - acc: 0.9094\n",
      "36000/36000 [==============================] - 17s 486us/step\n",
      "Accuracy is 0.9226388888888889\n",
      "Epoch 1/1\n",
      "36000/36000 [==============================] - 57s 2ms/step - loss: 0.2089 - acc: 0.9223\n",
      "36000/36000 [==============================] - 17s 485us/step\n",
      "Accuracy is 0.9295\n",
      "Epoch 1/1\n",
      "36000/36000 [==============================] - 58s 2ms/step - loss: 0.2042 - acc: 0.9253\n",
      "36000/36000 [==============================] - 18s 488us/step\n",
      "Accuracy is 0.92425\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-55343424015e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./bin/pulse_generation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/final.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mshuffle_in_unison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc=0\n",
    "while(acc<0.95):\n",
    "    \n",
    "    os.system(\"./bin/pulse_generation\")\n",
    "    train_X = loadtxt('data/final.csv')\n",
    "    y = append(zeros(int(len(train_X)/2)),ones(int(len(train_X)/2)))\n",
    "    shuffle_in_unison(train_X,y)\n",
    "    trap_ = fft_trapezoid(10,0,1250.)\n",
    "    for i in range(len(train_X)):\n",
    "        train_X[i] -= mean(train_X[i][:900])\n",
    "        train_X[i] = fft.irfft(trap_*fft.rfft(train_X[i]))\n",
    "        train_X[i] = train_X[i]/max(train_X[i])\n",
    "    x = train_X.reshape(len(train_X),wavelen,1)\n",
    "    \n",
    "    no_drop.fit(x,y,batch_size=32,epochs=1)\n",
    "    \n",
    "    acc = no_drop.evaluate(val_x,val_y)[1]\n",
    "    print(\"Accuracy is \"+str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"./bin/pulse_generation\")\n",
    "train_X = loadtxt('data/final.csv')\n",
    "y = append(zeros(int(len(train_X)/2)),ones(int(len(train_X)/2)))\n",
    "shuffle_in_unison(train_X,y)\n",
    "trap_ = fft_trapezoid(10,0,1250.)\n",
    "for i in range(len(train_X)):\n",
    "    train_X[i] -= mean(train_X[i][:900])\n",
    "    train_X[i] = fft.irfft(trap_*fft.rfft(train_X[i]))\n",
    "    train_X[i] = train_X[i]/max(train_X[i])\n",
    "val_x = train_X.reshape(len(train_X),wavelen,1)\n",
    "val_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 17s 483us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21198623688187865, 0.9221111111111111]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_drop.evaluate(val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"./aaron_gen/bin/pulse_generation\")\n",
    "train_X = loadtxt('./aaron_gen/data/final.csv')\n",
    "y = append(zeros(int(len(train_X)/2)),ones(int(len(train_X)/2)))\n",
    "shuffle_in_unison(train_X,y)\n",
    "trap_ = fft_trapezoid(10,0,1250.)\n",
    "for i in range(len(train_X)):\n",
    "    train_X[i] -= mean(train_X[i][:900])\n",
    "    train_X[i] = fft.irfft(trap_*fft.rfft(train_X[i]))\n",
    "    train_X[i] = train_X[i]/max(train_X[i])\n",
    "val_x = train_X.reshape(len(train_X),wavelen,1)\n",
    "val_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 548us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4871486673355103, 0.782]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_drop.evaluate(val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
