{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal filtering\n",
    "### The point of this is to train with a few different filtering methods and compare\n",
    "### Result: trapezoidal filter is best\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import clock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "random.seed(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelen=3500\n",
    "noise_rms=20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_synth_pulse(amp, T0, wf):\n",
    "    length = len(wf)\n",
    "    cc_slow = 2.5; cc_slow=cc_slow/(cc_slow+1); ##charge collection slow time constant\n",
    "\n",
    "    cc_fast = 1./2.5; #charge collection fast time constant\n",
    "    alpha_cr = 1250./(1250.+1.); #fall time of output\n",
    "    alpha_rc1 = 1./2.75;\n",
    "    alpha_rc2 = 1./2.75;\n",
    "    step=zeros(2);charge=zeros(2);cur_s=zeros(2);cur_f=zeros(2);cr=zeros(2);rc1=zeros(2);rc2=zeros(2);\n",
    "    for i in range(length):\n",
    "        if i>=T0:\n",
    "            step[i%2]=1.\n",
    "        else:\n",
    "            step[i%2]=0.\n",
    "        cur_s[i%2]=cc_slow*(cur_s[(i+1)%2]+step[i%2]-step[(i+1)%2]);\n",
    "        cur_f[i%2]=cc_fast*(cur_s[i%2]-cur_f[(i+1)%2])+cur_f[(i+1)%2];\n",
    "        charge[i%2]=charge[(i+1)%2]+amp*cur_f[i%2]*(1./cc_slow-1.);\n",
    "        cr[i%2]=alpha_cr*(cr[(i+1)%2]+charge[i%2]-charge[(i+1)%2]);\n",
    "        rc1[i%2]=alpha_rc1*(cr[i%2]-rc1[(i+1)%2])+rc1[(i+1)%2];\n",
    "        rc2[i%2]=alpha_rc2*(rc1[i%2]-rc2[(i+1)%2])+rc2[(i+1)%2];\n",
    "        wf[i]=rc2[i%2];\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    rng_state = random.get_state()\n",
    "    random.shuffle(a)\n",
    "    random.set_state(rng_state)\n",
    "    random.shuffle(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_trapezoid(rise_time, flat_top , tau):\n",
    "    length = wavelen\n",
    "    length = length+2*rise_time+flat_top;\n",
    "    p = zeros(length)\n",
    "    s = zeros(length)\n",
    "    input2 = zeros(length)\n",
    "    p[0] = s[0] = input2[0] = 0.;\n",
    "    for i in range(1,length):\n",
    "        input2[i] = s[i] = 0.;\n",
    "    input2[1]=1.;\n",
    "    tau = 1/(exp(1./tau)-1);\n",
    "    for i in range(1,length):\n",
    "        if i>=2*rise_time+flat_top:\n",
    "            d = input2[i]-input2[i-rise_time]-input2[i-rise_time-flat_top]+input2[i-2*rise_time-flat_top]\n",
    "        else:\n",
    "            if i>=rise_time+flat_top:\n",
    "                d = input2[i]-input2[i-rise_time]-input2[i-rise_time-flat_top]\n",
    "            else:\n",
    "                if i>=rise_time:\n",
    "                    d = input2[i]-input2[i-rise_time]\n",
    "                else:\n",
    "                    d = input2[i];\n",
    "        p[i] = p[i-1]+d;\n",
    "        s[i] = s[i-1]+p[i]+tau*d;\n",
    "    for i in range(length):\n",
    "        s[i] = s[i]/(rise_time*tau);\n",
    "    \n",
    "    res = fft.rfft(s)\n",
    "    return res[:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_cusp(shape_time, tau):\n",
    "    length=wavelen\n",
    "    k=2*shape_time+1;\n",
    "    length = length+k;  \n",
    "    m2=1.; \n",
    "    m1=m2/(exp(1./tau)-1.);\n",
    "    p = empty(length)\n",
    "    q = empty(length)\n",
    "    s = empty(length)\n",
    "    input_ = zeros(length)\n",
    "    p[0]=q[0]=s[0]=input_[0]=0.\n",
    "    input_[1]=1.\n",
    "    dk=0.\n",
    "    dl=0.\n",
    "    for i in range(1,length):\n",
    "        dk=0.\n",
    "        dl=0.\n",
    "        dk = input_[i]\n",
    "        if i>=k:\n",
    "            dk -= input_[i-k]\n",
    "\n",
    "        if i>=shape_time:\n",
    "            dl += input_[i-shape_time]\n",
    "\n",
    "        if i>=shape_time+1:\n",
    "            dl -= input_[i-shape_time-1]\n",
    "\n",
    "        \n",
    "        p[i] = p[i-1]+dk-k*dl;\n",
    "        q[i] = q[i-1]+m2*p[i];\n",
    "        s[i] = s[i-1]+q[i]+m1*p[i];\n",
    "    for i in range(length):\n",
    "        s[i] = s[i]/(0.5*shape_time*(shape_time+1)*m1);\n",
    "    res = fft.rfft(s)\n",
    "    return res[:-1*shape_time];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Gen defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(batchsize):\n",
    "    # speedy function without rise time spread and without noise spectrum\n",
    "    # also increased visibility of delay \n",
    "    energies = random.random(batchsize)*2500\n",
    "    delays = random.random(batchsize)*200+8\n",
    "    percent = random.random(batchsize)\n",
    "    #T0s = random.normal(loc=1000, scale=30, size=batchsize).round().astype(int)\n",
    "    T0s = random.randint(900,1101,batchsize)\n",
    "        \n",
    "    rand_choices = empty((batchsize,3))\n",
    "    rand_choices[:,0] = energies\n",
    "    rand_choices[:,1] = delays\n",
    "    rand_choices[:,2] = percent\n",
    "    \n",
    "    X = empty((batchsize,wavelen))\n",
    "    y = append( ones(int(batchsize/2)), zeros(batchsize-int(batchsize/2)))\n",
    "    \n",
    "    noise = random.normal(scale=noise_rms,size=(batchsize,wavelen))\n",
    "    tmp = empty(wavelen)\n",
    "    tmp2= empty(wavelen)\n",
    "    for i in range(int(batchsize/2)):\n",
    "        gen_synth_pulse(rand_choices[i][0]*rand_choices[i][2],T0s[i],tmp)\n",
    "        gen_synth_pulse(rand_choices[i][0]*(1-rand_choices[i][2]),T0s[i]+rand_choices[i][1]/4,tmp2)\n",
    "        X[i] = tmp+tmp2+noise[i]\n",
    "    for i in range(int(batchsize/2),batchsize):\n",
    "        gen_synth_pulse(rand_choices[i][0],T0s[i],tmp)\n",
    "        X[i] = tmp+noise[i]\n",
    "        \n",
    "    shuffle_in_unison(X,y)\n",
    "    return X.reshape(batchsize,wavelen,1),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trap_gen_batch(batchsize):\n",
    "    # trapezoid filter version...\n",
    "    # speedy function without rise time spread and without noise spectrum\n",
    "    energies = random.random(batchsize)*2500\n",
    "    delays = random.random(batchsize)*200+8\n",
    "    percent = random.random(batchsize)\n",
    "    #T0s = random.normal(loc=1000, scale=30, size=batchsize).round().astype(int)\n",
    "    T0s = random.randint(900,1101,batchsize)\n",
    "\n",
    "    rand_choices = empty((batchsize,3))\n",
    "    rand_choices[:,0] = energies\n",
    "    rand_choices[:,1] = delays\n",
    "    rand_choices[:,2] = percent\n",
    "    \n",
    "    X = empty((batchsize,wavelen))\n",
    "    y = append( ones(int(batchsize/2)), zeros(batchsize-int(batchsize/2)))\n",
    "    \n",
    "    noise = random.normal(scale=noise_rms,size=(batchsize,wavelen))\n",
    "    tmp = empty(wavelen)\n",
    "    tmp2= empty(wavelen)\n",
    "    trap_ = fft_trapezoid(100,0,1250.)\n",
    "    \n",
    "    # generate an 1:1 ratio of pileup to no pileup then shuffle them\n",
    "    for i in range(int(batchsize/2)):\n",
    "        gen_synth_pulse(rand_choices[i][0]*rand_choices[i][2],T0s[i],tmp)\n",
    "        gen_synth_pulse(rand_choices[i][0]*(1-rand_choices[i][2]),T0s[i]+rand_choices[i][1]/4,tmp2)\n",
    "        X[i] = fft.irfft(trap_*fft.rfft(tmp+tmp2+noise[i]))\n",
    "    for i in range(int(batchsize/2),batchsize):\n",
    "        gen_synth_pulse(rand_choices[i][0],T0s[i],tmp)\n",
    "        X[i] = fft.irfft(trap_*fft.rfft(tmp+noise[i]))\n",
    "        \n",
    "    shuffle_in_unison(X,y)\n",
    "    return X.reshape(batchsize,wavelen,1),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cusp_gen_batch(batchsize):\n",
    "    # cusp filter version...\n",
    "    # speedy function without rise time spread and without noise spectrum\n",
    "    energies = random.random(batchsize)*2500\n",
    "    delays = random.random(batchsize)*200+8\n",
    "    percent = random.random(batchsize)\n",
    "    T0s = random.randint(900,1101,batchsize)\n",
    "\n",
    "    #T0s = random.normal(loc=1000, scale=30, size=batchsize).round().astype(int)\n",
    "\n",
    "    rand_choices = empty((batchsize,3))\n",
    "    rand_choices[:,0] = energies\n",
    "    rand_choices[:,1] = delays\n",
    "    rand_choices[:,2] = percent\n",
    "    \n",
    "    X = empty((batchsize,wavelen))\n",
    "    y = append( ones(int(batchsize/2)), zeros(batchsize-int(batchsize/2)))\n",
    "    \n",
    "    noise = random.normal(scale=noise_rms,size=(batchsize,wavelen))\n",
    "    tmp = empty(wavelen)\n",
    "    tmp2= empty(wavelen)\n",
    "    cusp_ = fft_cusp(100,1250.)\n",
    "    # generate an 1:1 ratio of pileup to no pileup then shuffle them\n",
    "    for i in range(int(batchsize/2)):\n",
    "        gen_synth_pulse(rand_choices[i][0]*rand_choices[i][2],T0s[i],tmp)\n",
    "        gen_synth_pulse(rand_choices[i][0]*(1-rand_choices[i][2]),T0s[i]+rand_choices[i][1]/4,tmp2)\n",
    "        X[i] = fft.irfft(cusp_*fft.rfft(tmp+tmp2+noise[i]))\n",
    "    for i in range(int(batchsize/2),batchsize):\n",
    "        gen_synth_pulse(rand_choices[i][0],T0s[i],tmp)\n",
    "        X[i] = fft.irfft(cusp_*fft.rfft(tmp+noise[i]))\n",
    "        \n",
    "    shuffle_in_unison(X,y)\n",
    "    return X.reshape(batchsize,wavelen,1),y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_gen():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(256, 3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## def realistic data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_synth_pulse_realistic(amp, T0, wf):\n",
    "    length = len(wf)\n",
    "    cc_slow = 2.5+0.4*random.normal(); cc_slow=cc_slow/(cc_slow+1); ##charge collection slow time constant\n",
    "\n",
    "    cc_fast = 1./2.5; #charge collection fast time constant\n",
    "    alpha_cr = 1250./(1250.+1.); #fall time of output\n",
    "    alpha_rc1 = 1./2.75;\n",
    "    alpha_rc2 = 1./2.75;\n",
    "    step=zeros(2);charge=zeros(2);cur_s=zeros(2);cur_f=zeros(2);cr=zeros(2);rc1=zeros(2);rc2=zeros(2);\n",
    "    for i in range(length):\n",
    "        if i>=T0:\n",
    "            step[i%2]=1.\n",
    "        else:\n",
    "            step[i%2]=0.\n",
    "        cur_s[i%2]=cc_slow*(cur_s[(i+1)%2]+step[i%2]-step[(i+1)%2]);\n",
    "        cur_f[i%2]=cc_fast*(cur_s[i%2]-cur_f[(i+1)%2])+cur_f[(i+1)%2];\n",
    "        charge[i%2]=charge[(i+1)%2]+amp*cur_f[i%2]*(1./cc_slow-1.);\n",
    "        cr[i%2]=alpha_cr*(cr[(i+1)%2]+charge[i%2]-charge[(i+1)%2]);\n",
    "        rc1[i%2]=alpha_rc1*(cr[i%2]-rc1[(i+1)%2])+rc1[(i+1)%2];\n",
    "        rc2[i%2]=alpha_rc2*(rc1[i%2]-rc2[(i+1)%2])+rc2[(i+1)%2];\n",
    "        wf[i]=rc2[i%2];\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def superimpose_noise(wf, stdDev):\n",
    "    length=len(wf)\n",
    "    fin = open('power_spectrum.dat', 'r')\n",
    "    powerspectrum = array(str(fin.read()).split(), dtype=float64)\n",
    "    fin.close()\n",
    "    my_array = zeros((65533,2))\n",
    "    my_array[0][0]= -114.962\n",
    "    my_array[0][0]= 0.\n",
    "    for i in range(1,32767):\n",
    "        phase = 2.*pi*(random.randint(1, 10000000 + 1)%10000000)/10000000.\n",
    "        my_array[i][0]=powerspectrum[i-1]*cos(phase);\n",
    "        my_array[65532-i+1][0]=my_array[i][0]\n",
    "        my_array[i][1]=powerspectrum[i-1]*sin(phase);\n",
    "        my_array[65532-i+1][1]= -1*(my_array[i][1])\n",
    "    my_array = (my_array[:,0]+my_array[:,1].astype(complex_))\n",
    "    my_array = fft.irfft(my_array)\n",
    "    for i in range(length):\n",
    "        wf[i]= length*stdDev*my_array[i]*1.633953736 # adjusted factor here since fftw3 is unnormalized fft\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_realistic_batch(batchsize):\n",
    "    energies = random.random(batchsize)*2500\n",
    "    delays = random.random(batchsize)*200\n",
    "    percent = random.random(batchsize)\n",
    "    T0s = random.randint(900,1101,batchsize)\n",
    "    \n",
    "    rand_choices = empty((batchsize,3))\n",
    "    rand_choices[:,0] = energies\n",
    "    rand_choices[:,1] = delays\n",
    "    rand_choices[:,2] = percent\n",
    "    \n",
    "    X = empty((batchsize,wavelen))\n",
    "    y = append(ones(int(batchsize*0.5)), zeros(batchsize-int(batchsize*0.5)))\n",
    "    \n",
    "    tmp = empty(wavelen)\n",
    "    tmp2= empty(wavelen)\n",
    "    noise = empty(wavelen)\n",
    "\n",
    "    # generate an 1:1 ratio of pileup to no pileup then shuffle them\n",
    "    for i in range(int(batchsize*0.5)):\n",
    "        gen_synth_pulse_realistic(rand_choices[i][0]*rand_choices[i][2],T0s[i],tmp)\n",
    "        gen_synth_pulse_realistic(rand_choices[i][0]*(1-rand_choices[i][2]),T0s[i]+rand_choices[i][1]/4,tmp2)\n",
    "        superimpose_noise(noise,noise_rms)\n",
    "        X[i] = tmp+tmp2+noise\n",
    "    for i in range(int(batchsize*0.5),batchsize):\n",
    "        gen_synth_pulse_realistic(rand_choices[i][0],T0s[i],tmp)\n",
    "        superimpose_noise(noise,noise_rms)\n",
    "        X[i] = tmp+noise\n",
    "        \n",
    "    shuffle_in_unison(X,y)\n",
    "    return X.reshape(batchsize,wavelen,1),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_generic(X, fft_func, *args):\n",
    "    batchsize = len(X)\n",
    "    X_ = X.reshape(batchsize,wavelen).copy()\n",
    "    fft_filter = fft_func(*args)\n",
    "    for i in range(batchsize):\n",
    "        X_[i] = fft.irfft(fft.rfft(X_[i])*fft_filter)\n",
    "    return X_.reshape(batchsize,wavelen,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=2**10\n",
    "train_size=2**13\n",
    "real_test=True\n",
    "num_batch_size=32\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Realistic Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if real_test:\n",
    "    test_X, test_y = gen_realistic_batch(test_size)\n",
    "else:\n",
    "    test_X, test_y = gen_batch(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_trap = fft_generic(test_X, fft_trapezoid, 100,0,1250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_cusp = fft_generic(test_X, fft_cusp, 100,1250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = gen_batch(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = keras.callbacks.TensorBoard(log_dir='./logs/vanilla/')\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\"./logs/vanilla/weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8192 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "8192/8192 [==============================] - 16s 2ms/step - loss: 0.6949 - acc: 0.4932 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.6932 - acc: 0.4933 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.6932 - acc: 0.4971 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.6932 - acc: 0.4973 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.6932 - acc: 0.4990 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.6932 - acc: 0.4912 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.6932 - acc: 0.4954 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.6932 - acc: 0.4973 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.6932 - acc: 0.4954 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 10/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.6932 - acc: 0.4854 - val_loss: 0.6931 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_X,train_y, batch_size = num_batch_size, epochs=num_epochs, validation_data=(test_X,test_y), callbacks=[cp_callback,tb_callback]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 512],\n",
       "       [  0, 512]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y,array(around(model.predict(test_X).flatten(),0),dtype=int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 0s 478us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6931474208831787, 0.5]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trapezoid Filter CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,train_y = trap_gen_batch(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = keras.callbacks.TensorBoard(log_dir='./logs/trap/')\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\"./logs/trap/weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8192 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "8192/8192 [==============================] - 15s 2ms/step - loss: 0.6796 - acc: 0.5431 - val_loss: 0.6832 - val_acc: 0.5928\n",
      "Epoch 2/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.6119 - acc: 0.6504 - val_loss: 1.0082 - val_acc: 0.6387\n",
      "Epoch 3/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.5275 - acc: 0.7468 - val_loss: 1.3330 - val_acc: 0.6455\n",
      "Epoch 4/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.4771 - acc: 0.7754 - val_loss: 0.9171 - val_acc: 0.7266\n",
      "Epoch 5/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.4394 - acc: 0.8000 - val_loss: 1.4735 - val_acc: 0.6689\n",
      "Epoch 6/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.4166 - acc: 0.8108 - val_loss: 1.2034 - val_acc: 0.6914\n",
      "Epoch 7/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.4084 - acc: 0.8120 - val_loss: 0.9400 - val_acc: 0.7354\n",
      "Epoch 8/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.3903 - acc: 0.8185 - val_loss: 0.9514 - val_acc: 0.7266\n",
      "Epoch 9/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.3855 - acc: 0.8204 - val_loss: 1.7243 - val_acc: 0.6729\n",
      "Epoch 10/10\n",
      "8192/8192 [==============================] - 14s 2ms/step - loss: 0.3705 - acc: 0.8345 - val_loss: 1.0866 - val_acc: 0.7188\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_X,train_y, batch_size = num_batch_size, epochs=num_epochs, validation_data=(test_X_trap,test_y), callbacks=[cp_callback,tb_callback]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[388, 124],\n",
       "       [164, 348]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y,array(around(model.predict(test_X_trap).flatten(),0),dtype=int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 0s 480us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.086636658757925, 0.71875]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X_trap, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cusp Filter CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,train_y = cusp_gen_batch(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_callback = keras.callbacks.TensorBoard(log_dir='./logs/cusp/')\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\"./logs/cusp/weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8192 samples, validate on 1024 samples\n",
      "Epoch 1/10\n",
      "8192/8192 [==============================] - 15s 2ms/step - loss: 0.6890 - acc: 0.5305 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "8192/8192 [==============================] - 15s 2ms/step - loss: 0.6801 - acc: 0.5386 - val_loss: 0.6865 - val_acc: 0.5410\n",
      "Epoch 3/10\n",
      "8192/8192 [==============================] - 15s 2ms/step - loss: 0.6536 - acc: 0.5911 - val_loss: 0.7431 - val_acc: 0.5303\n",
      "Epoch 4/10\n",
      "8192/8192 [==============================] - 15s 2ms/step - loss: 0.6375 - acc: 0.6262 - val_loss: 0.7866 - val_acc: 0.5322\n",
      "Epoch 5/10\n",
      "8192/8192 [==============================] - 15s 2ms/step - loss: 0.6243 - acc: 0.6572 - val_loss: 1.2911 - val_acc: 0.5020\n",
      "Epoch 6/10\n",
      "8192/8192 [==============================] - 15s 2ms/step - loss: 0.6146 - acc: 0.6666 - val_loss: 1.2353 - val_acc: 0.5195\n",
      "Epoch 7/10\n",
      "8192/8192 [==============================] - 15s 2ms/step - loss: 0.6100 - acc: 0.6709 - val_loss: 1.0403 - val_acc: 0.5576\n",
      "Epoch 8/10\n",
      "8192/8192 [==============================] - 15s 2ms/step - loss: 0.6040 - acc: 0.6805 - val_loss: 0.8621 - val_acc: 0.6025\n",
      "Epoch 9/10\n",
      "8192/8192 [==============================] - 15s 2ms/step - loss: 0.5907 - acc: 0.6868 - val_loss: 1.1752 - val_acc: 0.5557\n",
      "Epoch 10/10\n",
      "8192/8192 [==============================] - 15s 2ms/step - loss: 0.5801 - acc: 0.7019 - val_loss: 1.9296 - val_acc: 0.5322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6902d752b0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X,train_y, batch_size = num_batch_size, epochs=num_epochs, validation_data=(test_X_cusp,test_y), callbacks=[cp_callback,tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[456,  56],\n",
       "       [423,  89]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y,array(around(model.predict(test_X_cusp).flatten(),0),dtype=int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 1s 506us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9296416975557804, 0.5322265625]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X_cusp, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
