{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from os import system as sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_trapezoid(length, rise_time, flat_top , tau):\n",
    "    length = length+2*rise_time+flat_top;\n",
    "    p = np.zeros(length)\n",
    "    s = np.zeros(length)\n",
    "    input2 = np.zeros(length)\n",
    "    p[0] = s[0] = input2[0] = 0.;\n",
    "    for i in range(1,length):\n",
    "        input2[i] = s[i] = 0.;\n",
    "    input2[1]=1.;\n",
    "    tau = 1/(np.exp(1./tau)-1);\n",
    "    for i in range(1,length):\n",
    "        if i>=2*rise_time+flat_top:\n",
    "            d = input2[i]-input2[i-rise_time]-input2[i-rise_time-flat_top]+input2[i-2*rise_time-flat_top]\n",
    "        else:\n",
    "            if i>=rise_time+flat_top:\n",
    "                d = input2[i]-input2[i-rise_time]-input2[i-rise_time-flat_top]\n",
    "            else:\n",
    "                if i>=rise_time:\n",
    "                    d = input2[i]-input2[i-rise_time]\n",
    "                else:\n",
    "                    d = input2[i];\n",
    "        p[i] = p[i-1]+d;\n",
    "        s[i] = s[i-1]+p[i]+tau*d;\n",
    "    for i in range(length):\n",
    "        s[i] = s[i]/(rise_time*tau);\n",
    "    \n",
    "    res = np.fft.rfft(s)\n",
    "    return res[:-(flat_top+rise_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, batch_size=32, dim=(3500,1), n_channels=1, n_classes=1, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(len(self.X)/self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation()\n",
    "\n",
    "        return X, y\n",
    "    def shuffle_in_unison(self, a, b):\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(a)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(b)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        sys('../data_generator/bin/pulse_generation /dev/null my_data.dat')\n",
    "        my_data = np.loadtxt('my_data.dat')\n",
    "        my_labels = np.append(np.zeros(int(len(my_data)/2)),np.ones(int(len(my_data)/2)))\n",
    "        trap=fft_trapezoid(3500, 20,0,1250)\n",
    "        self.X = np.empty((len(my_data), 800))\n",
    "        for i in range(len(my_data)):\n",
    "            self.X[i] = np.fft.irfft(trap*np.fft.rfft(my_data[i]))[700:1500]\n",
    "        self.X = self.X.reshape(len(my_data), 800, 1)\n",
    "        #y = convert_to_one_hot(my_labels.astype(int64), 2).T\n",
    "        self.y = my_labels\n",
    "        sys('rm my_data.dat')\n",
    "        if (self.shuffle):\n",
    "            self.shuffle_in_unison(self.X, self.y)\n",
    "        self.index=0\n",
    "        \n",
    "\n",
    "    def __data_generation(self):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X_tmp = self.X[self.index*self.batch_size:(self.index+1)*self.batch_size]\n",
    "        y_tmp = self.y[self.index*self.batch_size:(self.index+1)*self.batch_size]\n",
    "        self.index += 1\n",
    "        return X_tmp, y_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, batch_size=32, dim=(3500,1), n_channels=1, n_classes=1, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.epoch = 0\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(len(self.X)/self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation()\n",
    "        return X, y\n",
    "    \n",
    "    def shuffle_in_unison(self, a, b):\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(a)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(b)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if (self.epoch % 5 == 0):\n",
    "            num = int(self.epoch/5)\n",
    "            'Updates indexes after each epoch'\n",
    "            my_data = np.loadtxt('../data/'+str(num+1)+'.dat')\n",
    "            my_labels = np.append(np.zeros(int(len(my_data)/2)),np.ones(int(len(my_data)/2)))\n",
    "            trap=fft_trapezoid(3500, 20,0,1250)\n",
    "            self.X = np.empty((len(my_data), 800))\n",
    "            for i in range(len(my_data)):\n",
    "                my_data[i] = np.fft.irfft(trap*np.fft.rfft(my_data[i]))\n",
    "                self.X[i] = self.X[i] - np.mean(my_data[i][:100])\n",
    "                self.X[i] = self.X[i]/max(self.X[i])\n",
    "            self.X = self.X.reshape(len(my_data), 800, 1)\n",
    "            #y = convert_to_one_hot(my_labels.astype(int64), 2).T\n",
    "            self.y = my_labels            \n",
    "        self.shuffle_in_unison(self.X, self.y)\n",
    "        self.index=0\n",
    "        self.epoch += 1\n",
    "        \n",
    "\n",
    "    def __data_generation(self):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X_tmp = self.X[self.index*self.batch_size:(self.index+1)*self.batch_size]\n",
    "        y_tmp = self.y[self.index*self.batch_size:(self.index+1)*self.batch_size]\n",
    "        self.index += 1\n",
    "        return X_tmp, y_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
